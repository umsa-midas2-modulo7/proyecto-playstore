{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f35035",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_ids = [\n",
    "    \"com.bancosol.altoke\", \n",
    "    \"com.bcp.bo.wallet\", \n",
    "    \"bo.com.yolopago\", \n",
    "    \"com.busa.wallet\", \n",
    "    \"com.walletapp.mobile\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2cd943",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script de Recolecci√≥n Inicial - Apps Bolivia\n",
    "Ejecutar UNA SOLA VEZ para obtener todo el historial de comentarios\n",
    "\"\"\"\n",
    "\n",
    "# Configuraci√≥n de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'scraping_inicial_{datetime.now().strftime(\"%Y%m%d\")}.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class InitialScraper:\n",
    "    def __init__(self):\n",
    "        \"\"\"Configuraci√≥n espec√≠fica para recolecci√≥n inicial\"\"\"\n",
    "        self.country = 'bo'  \n",
    "        self.lang = 'es'     \n",
    "        self.base_delay = (8, 15)  # Delays para recolecci√≥n masiva\n",
    "        self.max_retries = 3\n",
    "        self.output_dir = \"../data/initial_reviews\"\n",
    "        self.session_requests = 0\n",
    "        \n",
    "    def scrape_app_complete(self, app_id):\n",
    "        \"\"\"\n",
    "        Recolecta TODOS los comentarios hist√≥ricos de una app\n",
    "        \n",
    "        Args:\n",
    "            app_id (str): ID de la aplicaci√≥n (ej: 'com.whatsapp')\n",
    "            \n",
    "        Returns:\n",
    "            list: todos los comentarios encontrados\n",
    "        \"\"\"\n",
    "        logger.info(f\"üöÄ INICIANDO RECOLECCI√ìN COMPLETA: {app_id}\")\n",
    "        \n",
    "        all_reviews = []\n",
    "        token = None\n",
    "        page_count = 0\n",
    "        consecutive_errors = 0\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Request a Google Play Store\n",
    "                result, token = reviews(\n",
    "                    app_id,\n",
    "                    lang=self.lang,\n",
    "                    country=self.country,\n",
    "                    sort=Sort.NEWEST,  # M√°s recientes primero\n",
    "                    count=200,         # M√°ximo por request\n",
    "                    continuation_token=token\n",
    "                )\n",
    "                \n",
    "                self.session_requests += 1\n",
    "                \n",
    "                # Verificar si hay resultados\n",
    "                if not result:\n",
    "                    logger.info(f\"üìÑ P√°gina {page_count}: Sin m√°s comentarios\")\n",
    "                    break\n",
    "                \n",
    "                # Validar calidad de datos\n",
    "                valid_reviews = self._validate_reviews(result, app_id)\n",
    "                all_reviews.extend(valid_reviews)\n",
    "                page_count += 1\n",
    "                \n",
    "                logger.info(f\"üìÑ P√°gina {page_count}: {len(result)} comentarios | \"\n",
    "                           f\"V√°lidos: {len(valid_reviews)} | Total: {len(all_reviews)}\")\n",
    "                \n",
    "                # Sin token = fin de datos\n",
    "                if not token:\n",
    "                    logger.info(\"‚úÖ Token agotado - recolecci√≥n completa\")\n",
    "                    break\n",
    "                \n",
    "                consecutive_errors = 0  # Reset contador de errores\n",
    "                \n",
    "                # Delay inteligente\n",
    "                self._smart_delay(page_count)\n",
    "                \n",
    "            except Exception as e:\n",
    "                consecutive_errors += 1\n",
    "                logger.warning(f\"‚ö†Ô∏è Error p√°gina {page_count}: {str(e)}\")\n",
    "                \n",
    "                if consecutive_errors >= self.max_retries:\n",
    "                    logger.error(f\"‚ùå M√°ximo de errores alcanzado para {app_id}\")\n",
    "                    break\n",
    "                \n",
    "                # Delay por error (exponencial)\n",
    "                error_delay = min(120, 20 * (2 ** consecutive_errors))\n",
    "                logger.info(f\"üò¥ Esperando {error_delay}s por error...\")\n",
    "                time.sleep(error_delay)\n",
    "        \n",
    "        duration = datetime.now() - start_time\n",
    "        logger.info(f\"üéØ COMPLETADO {app_id}: {len(all_reviews)} comentarios en {duration}\")\n",
    "        \n",
    "        return all_reviews\n",
    "    \n",
    "    def _validate_reviews(self, reviews_batch, app_id):\n",
    "        \"\"\"Valida calidad de datos de comentarios\"\"\"\n",
    "        valid_reviews = []\n",
    "        issues = {'sin_contenido': 0, 'sin_fecha': 0, 'sin_puntuacion': 0}\n",
    "        \n",
    "        for review in reviews_batch:\n",
    "            is_valid = True\n",
    "            \n",
    "            # Verificar contenido\n",
    "            if not review.get('content') or len(review['content'].strip()) < 5:\n",
    "                issues['sin_contenido'] += 1\n",
    "                is_valid = False\n",
    "            \n",
    "            # Verificar fecha\n",
    "            if not review.get('at') or not isinstance(review['at'], datetime):\n",
    "                issues['sin_fecha'] += 1\n",
    "                is_valid = False\n",
    "            \n",
    "            # Verificar puntuaci√≥n\n",
    "            if review.get('score') is None or not (1 <= review.get('score', 0) <= 5):\n",
    "                issues['sin_puntuacion'] += 1\n",
    "                is_valid = False\n",
    "            \n",
    "            if is_valid:\n",
    "                # Agregar metadatos √∫tiles\n",
    "                review['app_id'] = app_id\n",
    "                review['scraped_at'] = datetime.now()\n",
    "                review['content_length'] = len(review['content'])\n",
    "                valid_reviews.append(review)\n",
    "        \n",
    "        # Log de issues si existen\n",
    "        if sum(issues.values()) > 0:\n",
    "            logger.warning(f\"‚ö†Ô∏è Issues encontrados: {issues}\")\n",
    "        \n",
    "        return valid_reviews\n",
    "    \n",
    "    def _smart_delay(self, page_count):\n",
    "        \"\"\"Sistema de delays inteligente para evitar bloqueos\"\"\"\n",
    "        base_min, base_max = self.base_delay\n",
    "        \n",
    "        # Incremento gradual por volumen de requests\n",
    "        volume_multiplier = 1 + (self.session_requests // 100) * 0.3\n",
    "        \n",
    "        # Delays especiales en puntos cr√≠ticos\n",
    "        if page_count % 25 == 0:  # Cada 25 p√°ginas (5000 comentarios)\n",
    "            special_delay = random.uniform(45, 90)\n",
    "            logger.info(f\"üõë PAUSA ESPECIAL (p√°gina {page_count}): {special_delay:.1f}s\")\n",
    "            time.sleep(special_delay)\n",
    "            return\n",
    "        \n",
    "        # Delay normal con variaci√≥n\n",
    "        normal_delay = random.uniform(\n",
    "            base_min * volume_multiplier,\n",
    "            base_max * volume_multiplier\n",
    "        )\n",
    "        \n",
    "        logger.debug(f\"‚è≥ Delay: {normal_delay:.1f}s\")\n",
    "        time.sleep(normal_delay)\n",
    "    \n",
    "    def save_complete_data(self, reviews, app_id):\n",
    "        \"\"\"\n",
    "        Guarda datos completos con metadata rica\n",
    "        \"\"\"\n",
    "        if not reviews:\n",
    "            logger.warning(f\"‚ùå Sin datos para guardar: {app_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Crear directorio\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        # DataFrame con datos completos\n",
    "        df = pd.DataFrame(reviews)\n",
    "        \n",
    "        # Estad√≠sticas pre-guardado\n",
    "        stats = self._generate_stats(df, app_id)\n",
    "        \n",
    "        # Archivo principal con timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        main_file = f\"{app_id}_complete_{timestamp}.csv\"\n",
    "        main_path = os.path.join(self.output_dir, main_file)\n",
    "        \n",
    "        # Guardar CSV principal\n",
    "        df.to_csv(main_path, index=False, encoding=\"utf-8-sig\")\n",
    "        \n",
    "        # Guardar archivo de estad√≠sticas\n",
    "        stats_file = f\"{app_id}_stats_{timestamp}.txt\"\n",
    "        stats_path = os.path.join(self.output_dir, stats_file)\n",
    "        \n",
    "        with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(stats)\n",
    "        \n",
    "        logger.info(\"üíæ GUARDADO EXITOSO:\")\n",
    "        logger.info(f\"   üìÅ Datos: {main_file}\")\n",
    "        logger.info(f\"   üìä Stats: {stats_file}\")\n",
    "        \n",
    "        return main_path\n",
    "    \n",
    "    def _generate_stats(self, df, app_id):\n",
    "        \"\"\"Genera estad√≠sticas detalladas\"\"\"\n",
    "        stats_text = f\"\"\"\n",
    "ESTAD√çSTICAS DE RECOLECCI√ìN INICIAL\n",
    "=====================================\n",
    "App ID: {app_id}\n",
    "Fecha de scraping: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "VOLUMEN DE DATOS:\n",
    "‚Ä¢ Total comentarios: {len(df):,}\n",
    "‚Ä¢ Rango temporal: {df['at'].min().date()} ‚Üí {df['at'].max().date()}\n",
    "‚Ä¢ D√≠as cubiertos: {(df['at'].max() - df['at'].min()).days}\n",
    "\n",
    "DISTRIBUCI√ìN DE PUNTUACIONES:\n",
    "\"\"\"\n",
    "        \n",
    "        for score in range(1, 6):\n",
    "            count = len(df[df['score'] == score])\n",
    "            percentage = (count / len(df)) * 100\n",
    "            stats_text += f\"‚Ä¢ {score} estrellas: {count:,} ({percentage:.1f}%)\\n\"\n",
    "        \n",
    "        stats_text += f\"\"\"\n",
    "M√âTRICAS DE CONTENIDO:\n",
    "‚Ä¢ Promedio caracteres: {df['content_length'].mean():.0f}\n",
    "‚Ä¢ Comentario m√°s largo: {df['content_length'].max()} caracteres\n",
    "‚Ä¢ Comentario m√°s corto: {df['content_length'].min()} caracteres\n",
    "\n",
    "ACTIVIDAD TEMPORAL:\n",
    "‚Ä¢ Comentarios √∫ltimo mes: {len(df[df['at'] > datetime.now() - pd.DateOffset(months=1)]):,}\n",
    "‚Ä¢ Comentarios √∫ltimos 7 d√≠as: {len(df[df['at'] > datetime.now() - pd.DateOffset(days=7)]):,}\n",
    "‚Ä¢ Puntuaci√≥n promedio: {df['score'].mean():.2f}/5.0\n",
    "\"\"\"\n",
    "        \n",
    "        return stats_text\n",
    "\n",
    "def main():\n",
    "    \"\"\"Funci√≥n principal para ejecutar recolecci√≥n inicial\"\"\"\n",
    "    \n",
    "    # üîß CONFIGURAR AQU√ç TUS APP IDs\n",
    "    # app_ids esta definida una celda arriba\n",
    "    \n",
    "    if not app_ids:\n",
    "        logger.warning(\"‚ö†Ô∏è CONFIGURAR app_ids en la variable antes de ejecutar\")\n",
    "        print(\"\\nüìã Para usar este script:\")\n",
    "        print(\"1. Edita la variable 'app_ids' en main()\")\n",
    "        print(\"2. Agrega los IDs de las apps bolivianas a analizar\")\n",
    "        print(\"3. Ejecuta: python initial_scraper.py\")\n",
    "        return\n",
    "    \n",
    "    scraper = InitialScraper()\n",
    "    results = {}\n",
    "    \n",
    "    logger.info(f\"üéØ INICIANDO RECOLECCI√ìN INICIAL DE {len(app_ids)} APPS\")\n",
    "    logger.info(\"üìç Pa√≠s: Bolivia | Idioma: Espa√±ol\")\n",
    "    \n",
    "    for i, app_id in enumerate(app_ids, 1):\n",
    "        logger.info(f\"\\n{'='*60}\")\n",
    "        logger.info(f\"üì± PROCESANDO APP {i}/{len(app_ids)}: {app_id}\")\n",
    "        logger.info(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # Recolectar todos los comentarios\n",
    "            reviews = scraper.scrape_app_complete(app_id)\n",
    "            \n",
    "            if reviews:\n",
    "                # Guardar datos\n",
    "                saved_path = scraper.save_complete_data(reviews, app_id)\n",
    "                results[app_id] = {\n",
    "                    'status': 'success',\n",
    "                    'count': len(reviews),\n",
    "                    'file': saved_path\n",
    "                }\n",
    "                logger.info(f\"‚úÖ {app_id}: {len(reviews):,} comentarios guardados\")\n",
    "            else:\n",
    "                results[app_id] = {'status': 'no_data', 'count': 0, 'file': None}\n",
    "                logger.warning(f\"‚ö†Ô∏è {app_id}: Sin comentarios encontrados\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå ERROR CR√çTICO en {app_id}: {str(e)}\")\n",
    "            results[app_id] = {'status': 'error', 'count': 0, 'error': str(e)}\n",
    "        \n",
    "        # Pausa larga entre apps\n",
    "        if i < len(app_ids):\n",
    "            inter_app_delay = random.uniform(60, 120)  # 1-2 minutos entre apps\n",
    "            logger.info(f\"üîÑ Pausa entre apps: {inter_app_delay:.1f}s\")\n",
    "            time.sleep(inter_app_delay)\n",
    "    \n",
    "    # Resumen final\n",
    "    _print_final_summary(results)\n",
    "\n",
    "def _print_final_summary(results):\n",
    "    \"\"\"Imprime resumen final de la recolecci√≥n\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üéâ RECOLECCI√ìN INICIAL COMPLETADA\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    total_reviews = sum(r.get('count', 0) for r in results.values())\n",
    "    successful = sum(1 for r in results.values() if r.get('status') == 'success')\n",
    "    \n",
    "    print(\"üìä RESUMEN GENERAL:\")\n",
    "    print(f\"   ‚Ä¢ Apps procesadas: {len(results)}\")\n",
    "    print(f\"   ‚Ä¢ Apps exitosas: {successful}\")\n",
    "    print(f\"   ‚Ä¢ Total comentarios: {total_reviews:,}\")\n",
    "    \n",
    "    print(\"\\nüì± DETALLE POR APP:\")\n",
    "    for app_id, result in results.items():\n",
    "        status_icon = \"‚úÖ\" if result['status'] == 'success' else \"‚ùå\"\n",
    "        print(f\"   {status_icon} {app_id}: {result.get('count', 0):,} comentarios\")\n",
    "    \n",
    "    print(\"\\nüìÅ Archivos guardados en: ../data/initial_reviews/\")\n",
    "    print(f\"üìù Log completo en: scraping_inicial_{datetime.now().strftime('%Y%m%d')}.log\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
